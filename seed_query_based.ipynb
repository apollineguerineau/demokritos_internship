{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.classifier.hyde_similarity_classifier import HydeSimilarityClassifier\n",
    "from model.business_object.crawl_session import CrawlSession\n",
    "from model.business_object.page import Page\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url  \\\n",
      "0  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
      "1  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
      "2  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
      "3  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
      "4  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
      "\n",
      "                                               title  \\\n",
      "0  Inverse Design of ZIFs through Artificial Inte...   \n",
      "1  Exploring Propane/Propylene Separation through...   \n",
      "2  Towards a Generalizable Machine-Learned\\nPoten...   \n",
      "3  Molecular diffusion enhanced performance evalu...   \n",
      "4  Machine Learning-driven models for predicting ...   \n",
      "\n",
      "                                         description  score_sim  \\\n",
      "0  Artificial Intelligence (AI) benefits research...   0.888876   \n",
      "1  Propylene is a vital component for the petroch...   0.865408   \n",
      "2  Machine-learned Potentials (MLPs) have transfo...   0.864718   \n",
      "3  Molecular diffusion is a fundamental property ...   0.880348   \n",
      "4  This study advances the discourse on the appli...   0.856192   \n",
      "\n",
      "                                      get_with_query  \\\n",
      "0  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
      "1  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
      "2  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
      "3  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
      "4  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
      "\n",
      "                   time_fetch  is_seed  score_hyde  \n",
      "0  2024-11-20 15:30:39.428983    False    0.934894  \n",
      "1  2024-11-20 15:30:39.614658    False    0.923098  \n",
      "2  2024-11-20 15:30:39.768251    False    0.915012  \n",
      "3  2024-11-20 15:30:39.908374    False    0.935718  \n",
      "4  2024-11-20 15:30:40.054033    False    0.932324  \n"
     ]
    }
   ],
   "source": [
    "path_to_crawlers = \"/Users/apollineguerineau/Documents/ENSAI/3A/Greece/internship/eval/ML_MOF_Diffusion/crawlers_v1/\"\n",
    "# Charger les deux fichiers CSV\n",
    "csv1_path = path_to_crawlers + \"seed_query_based_sim_cos_thr_0.802_pages_50/fetched_pages.csv\"\n",
    "csv2_path = path_to_crawlers + \"seed_query_based_hyde_sim_cos_thr_0.882_pages_50/fetched_pages.csv\"\n",
    "\n",
    "csv1 = pd.read_csv(csv1_path)\n",
    "csv2 = pd.read_csv(csv2_path)\n",
    "\n",
    "merged_csv = pd.merge(\n",
    "    csv1,\n",
    "    csv2[[\"url\", \"score\"]],  # Garder uniquement 'url' et 'score' du deuxième CSV\n",
    "    on=\"url\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Renommer les colonnes 'score' respectives\n",
    "merged_csv.rename(columns={\"score_x\": \"score_sim\", \"score_y\": \"score_hyde\"}, inplace=True)\n",
    "\n",
    "# Sauvegarder le résultat si nécessaire\n",
    "merged_csv_path = path_to_crawlers + \"merged_csv.csv\"\n",
    "merged_csv.to_csv(merged_csv_path, index=False)\n",
    "print(merged_csv.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes sans score initialement : 15\n",
      "Traitement de l'index 25288\n",
      "Traitement de l'index 26122\n",
      "Traitement de l'index 26264\n",
      "Traitement de l'index 26379\n",
      "Traitement de l'index 26442\n",
      "Traitement de l'index 26449\n",
      "Traitement de l'index 26516\n",
      "Traitement de l'index 26581\n",
      "Traitement de l'index 27069\n",
      "Traitement de l'index 27105\n",
      "Traitement de l'index 27205\n",
      "Traitement de l'index 27224\n",
      "Traitement de l'index 27251\n",
      "Traitement de l'index 27252\n",
      "Traitement de l'index 27258\n",
      "Nombre de lignes sans score après mise à jour : 0\n"
     ]
    }
   ],
   "source": [
    "# Compter le nombre de lignes avec NaN dans la colonne 'score_hyde'\n",
    "\n",
    "classifier = HydeSimilarityClassifier(name_embed_model='intfloat/multilingual-e5-base')\n",
    "crawl_session = CrawlSession(session_name='', query='')\n",
    "crawl_session.hyde = {\n",
    "    'title': 'Enhancing Adsorption Capacities of Metal-Organic Frameworks through Deep Learning and Diffusivity Optimization',\n",
    "    'abstract': 'The discovery and optimization of metal-organic frameworks (MOFs) has been revolutionized by the integration of machine learning (ML) techniques with diffusivity modeling. This research aims to investigate the application of deep learning algorithms in predicting and optimizing the diffusivity properties of MOFs, leading to enhanced adsorption capacities. A comprehensive review of existing literature on ML-driven MOF design is conducted, followed by the development of a novel framework for integrating ML models with Monte Carlo simulations to predict diffusivity. The proposed framework is then validated using experimental data from various MOF materials, resulting in significant improvements in predicted and measured diffusivity values. The findings of this study have far-reaching implications for the design and optimization of COFs and ZIFs, enabling the creation of high-performance adsorbents for energy storage, gas separation, and catalysis applications.'\n",
    "}\n",
    "\n",
    "missing_score_hyde = merged_csv[merged_csv['score_hyde'].isna()]\n",
    "print(f\"Nombre de lignes sans score initialement : {len(missing_score_hyde)}\")\n",
    "\n",
    "for index, row in missing_score_hyde.iterrows():\n",
    "    print(f\"Traitement de l'index {index}\")\n",
    "    page = Page(url=row['url'], title=row['title'], description=row['description'])\n",
    "    score = classifier.attribute_score(crawl_session=crawl_session, page=page)\n",
    "    \n",
    "    # Mettre à jour le score dans merged_csv directement\n",
    "    merged_csv.loc[index, 'score_hyde'] = score\n",
    "\n",
    "# Sauvegarder le dataframe mis à jour\n",
    "merged_csv.to_csv(path_to_crawlers + \"merged_csv_with_score.csv\", index=False)\n",
    "\n",
    "# Vérification des valeurs manquantes\n",
    "remaining_missing = merged_csv['score_hyde'].isna().sum()\n",
    "print(f\"Nombre de lignes sans score après mise à jour : {remaining_missing}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_csv.rename(columns={'score_hyde': 'score'}, inplace=True)\n",
    "\n",
    "# # Supprimer la colonne 'score_sim'\n",
    "# merged_csv.drop(columns=['score_sim'], inplace=True)\n",
    "\n",
    "# Afficher les 5 premières lignes pour vérifier les modifications\n",
    "merged_csv.head()\n",
    "\n",
    "merged_csv.to_csv(path_to_crawlers + \"seed_query_based_hyde_sim_cos_thr_0.882_pages_50/fetched_pages.csv\", index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "csv_test = merged_csv.head()\n",
    "print(len(csv_test))\n",
    "csv_test.to_csv(path_to_crawlers + \"seed_query_based_hyde_sim_cos_thr_0.882_pages_50/fetched_pages.csv\", index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Chemin du fichier de sortie\n",
    "output_file = path_to_crawlers + \"seed_query_based_hyde_sim_cos_thr_0.882_pages_50/fetched_pages.csv\"\n",
    "\n",
    "# Colonnes à inclure dans le fichier CSV\n",
    "columns = merged_csv.columns.tolist()\n",
    "\n",
    "# Ouvrir le fichier en mode écriture\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=columns)\n",
    "    \n",
    "    # Écrire l'en-tête\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Écrire chaque ligne\n",
    "    for _, row in merged_csv.iterrows():\n",
    "        writer.writerow(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>get_with_query</th>\n",
       "      <th>time_fetch</th>\n",
       "      <th>is_seed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://chemrxiv.org/engage/chemrxiv/article-d...</td>\n",
       "      <td>Inverse Design of ZIFs through Artificial Inte...</td>\n",
       "      <td>Artificial Intelligence (AI) benefits research...</td>\n",
       "      <td>\"Machine Learning\" AND (diffusion OR diffusivi...</td>\n",
       "      <td>2024-11-20 15:30:39.428983</td>\n",
       "      <td>False</td>\n",
       "      <td>0.934894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://chemrxiv.org/engage/chemrxiv/article-d...</td>\n",
       "      <td>Exploring Propane/Propylene Separation through...</td>\n",
       "      <td>Propylene is a vital component for the petroch...</td>\n",
       "      <td>\"Machine Learning\" AND (diffusion OR diffusivi...</td>\n",
       "      <td>2024-11-20 15:30:39.614658</td>\n",
       "      <td>False</td>\n",
       "      <td>0.923098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://chemrxiv.org/engage/chemrxiv/article-d...</td>\n",
       "      <td>Towards a Generalizable Machine-Learned\\nPoten...</td>\n",
       "      <td>Machine-learned Potentials (MLPs) have transfo...</td>\n",
       "      <td>\"Machine Learning\" AND (diffusion OR diffusivi...</td>\n",
       "      <td>2024-11-20 15:30:39.768251</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://chemrxiv.org/engage/chemrxiv/article-d...</td>\n",
       "      <td>Molecular diffusion enhanced performance evalu...</td>\n",
       "      <td>Molecular diffusion is a fundamental property ...</td>\n",
       "      <td>\"Machine Learning\" AND (diffusion OR diffusivi...</td>\n",
       "      <td>2024-11-20 15:30:39.908374</td>\n",
       "      <td>False</td>\n",
       "      <td>0.935718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://chemrxiv.org/engage/chemrxiv/article-d...</td>\n",
       "      <td>Machine Learning-driven models for predicting ...</td>\n",
       "      <td>This study advances the discourse on the appli...</td>\n",
       "      <td>\"Machine Learning\" AND (diffusion OR diffusivi...</td>\n",
       "      <td>2024-11-20 15:30:40.054033</td>\n",
       "      <td>False</td>\n",
       "      <td>0.932324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
       "1  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
       "2  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
       "3  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
       "4  https://chemrxiv.org/engage/chemrxiv/article-d...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Inverse Design of ZIFs through Artificial Inte...   \n",
       "1  Exploring Propane/Propylene Separation through...   \n",
       "2  Towards a Generalizable Machine-Learned\\nPoten...   \n",
       "3  Molecular diffusion enhanced performance evalu...   \n",
       "4  Machine Learning-driven models for predicting ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Artificial Intelligence (AI) benefits research...   \n",
       "1  Propylene is a vital component for the petroch...   \n",
       "2  Machine-learned Potentials (MLPs) have transfo...   \n",
       "3  Molecular diffusion is a fundamental property ...   \n",
       "4  This study advances the discourse on the appli...   \n",
       "\n",
       "                                      get_with_query  \\\n",
       "0  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
       "1  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
       "2  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
       "3  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
       "4  \"Machine Learning\" AND (diffusion OR diffusivi...   \n",
       "\n",
       "                   time_fetch  is_seed     score  \n",
       "0  2024-11-20 15:30:39.428983    False  0.934894  \n",
       "1  2024-11-20 15:30:39.614658    False  0.923098  \n",
       "2  2024-11-20 15:30:39.768251    False  0.915012  \n",
       "3  2024-11-20 15:30:39.908374    False  0.935718  \n",
       "4  2024-11-20 15:30:40.054033    False  0.932324  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_crawlers + \"seed_query_based_hyde_sim_cos_thr_0.882_pages_50/fetched_pages.csv\", sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/apollineguerineau/Documents/ENSAI/3A/Greece/internship/code/version0.2/demokritos_internship/seed_query_based.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/apollineguerineau/Documents/ENSAI/3A/Greece/internship/code/version0.2/demokritos_internship/seed_query_based.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/apollineguerineau/Documents/ENSAI/3A/Greece/internship/eval/ML_MOF_Diffusion/crawlers_v1/fetched_pages.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/apollineguerineau/Documents/ENSAI/3A/Greece/internship/code/version0.2/demokritos_internship/seed_query_based.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df\u001b[39m.\u001b[39mcolumns\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/apollineguerineau/Documents/ENSAI/3A/Greece/internship/eval/ML_MOF_Diffusion/crawlers_v1/fetched_pages.csv\", sep=',')\n",
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
